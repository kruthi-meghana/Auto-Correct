{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrect\n",
    "\n",
    "This application is to understand the most commonly used feature in any smart phone, it might be while texting, web-searching, or documenting. \n",
    "\n",
    "#### Things to achieve autocorrect system:\n",
    "\n",
    "   **Step 01:** Preparing the Dataset, vocabulary, and probability of each word in the corpus.\n",
    "\n",
    "   **Step 02:** Implementing the string manipulations like inserting, deleting, swaping, and replacing of letters.\n",
    "\n",
    "   **Step 03:** Performing all these string manipulations 'n' times.\n",
    "\n",
    "   **Step 04:** Calculate the `Minimum edit-distance`\n",
    "\n",
    "   **Step 05:**  Identify the top `n` suggestions (with higher probability).\n",
    "\n",
    "`Note: This is a simple autocorrect system that identifies the misspelled words and not the conextual meaning.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Preparing the Dataset\n",
    "\n",
    "First we need to prepare vocabulary which is extracted from the corpus given.\n",
    "\n",
    "I am using a basic corpus with 6k+ unique words, I am going to perform a RegEx to remove the unwanted punctuations etc.\n",
    "\n",
    "Next step, I would like to build the word_frequency dictionary  that basically has the frequency of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vocab():\n",
    "    file = open(\"corpus.txt\",\"r\")\n",
    "    \n",
    "    file_data = (file.readline()).lower()\n",
    "    words = []\n",
    "    while file_data:\n",
    "        words_list = re.findall(r\"\\w+\", file_data)\n",
    "        words.extend(words_list)\n",
    "        file_data = (file.readline()).lower()\n",
    "    word_frequency = Counter(words)   \n",
    "    return set(words), word_frequency #set removes the duplicates in your list hence forming our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words in our vocabulary 6116.\n",
      "The frequency of 'the' word: 1525.\n"
     ]
    }
   ],
   "source": [
    "vocabulary, word_frequency = prepare_vocab()\n",
    "print(f\"The number of unique words in our vocabulary {len(vocabulary)}.\")\n",
    "print(f\"The frequency of 'the' word: {word_frequency['the']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a probability dictionary, that mean probability of each word that it occurs randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_of_words(word_frequency):\n",
    "    total = sum(word_frequency.values())\n",
    "    word_probability = {key: value/total for key, value in word_frequency.items()}\n",
    "    return word_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words in our vocabulary 6116.\n",
      "The probability of 'the' word: 0.028444063117842356.\n"
     ]
    }
   ],
   "source": [
    "word_probability = probability_of_words(word_frequency)\n",
    "print(f\"The number of unique words in our vocabulary {len(word_probability)}.\")\n",
    "print(f\"The probability of 'the' word: {word_probability['the']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 String Manipulations\n",
    "\n",
    "Four main operations performed on the string to form the list of words that could be a possible replacement for the misspelled word are:\n",
    "\n",
    "* `Delete`\n",
    "* `Swap`\n",
    "* `Replace`\n",
    "* `Insert`\n",
    "\n",
    "## 2.0.1 Delete_manipulation\n",
    "\n",
    "`[('', 'loot'), ('l', 'oot'), ('lo', 'ot'), ('loo', 't'), ('loot', '')]`\n",
    "    \n",
    "We will divide the given word in to a tuple at each index forming the above list\n",
    "\n",
    "    1) First step will be to form a list of all possible tuples except the last combo.\n",
    "    2) Delete each letter from the give word and hence forming a list of different words:\n",
    "    \n",
    "        L + R[1:], there by deleting the letter R[0]\n",
    "        \n",
    "        ['oot', 'lot', 'lot', 'loo']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_manipulation(word):\n",
    "    word_tuples = [(word[:i],word[i:]) for i in range(len(word))] \n",
    "    return [L + R[1:] for L,R in word_tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oot', 'lot', 'lot', 'loo']\n"
     ]
    }
   ],
   "source": [
    "print(delete_manipulation(\"loot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0.2 Swap_manipulation\n",
    "\n",
    "`[('', 'loot'), ('l', 'oot'), ('lo', 'ot'), ('loo', 't'), ('loot', '')]`\n",
    "    \n",
    "We will divide the given word in to a tuple at each index forming the above list\n",
    "\n",
    "    1) First step will be to form a list of all possible tuples except the last combo.\n",
    "    2) Swap each letter with their neighboring letter forming a new string, append each string and return the list.\n",
    "    \n",
    "        For each tuple (L, R) we will return a new string where the string = L + swap(R[0] + R[1]) + R[2:]. \n",
    "        Resulting:\n",
    "        \n",
    "        ['olot', 'loot', 'loto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_manipulation(word):\n",
    "    \n",
    "    #Since the last tuple has no effect as R = \"\" we donot consider the range(len(R)+1)\n",
    "    \n",
    "    word_tuples = [(word[:i],word[i:]) for i in range(len(word))] \n",
    "    return [L+R[1]+R[0]+R[2:] for L, R in word_tuples if len(R) >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['olot', 'loot', 'loto']\n"
     ]
    }
   ],
   "source": [
    "print(swap_manipulation(\"loot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0.3 Replace_manipulations\n",
    "\n",
    "    \n",
    "    1) Prepare the list of tuples\n",
    "    2) Replacing each letter with \"abcdef....xyz\", for each tuple (L, R) we shall return L + C + R[1:] replacing R[0] with C\n",
    "    \n",
    "    \n",
    "`['aoot', 'boot', 'coot', 'doot', 'eoot', 'foot', 'goot', 'hoot', 'ioot', 'joot', 'koot', 'laot', 'lbot', 'lcot', 'ldot', 'leot', 'lfot', 'lgot', 'lhot', 'liot', 'ljot', 'lkot', 'llot', 'lmot', 'lnot', 'loat', 'lobt', 'loct', 'lodt', 'loet', 'loft', 'logt', 'loht', 'loit', 'lojt', 'lokt', 'lolt', 'lomt', 'lont', 'looa', 'loob', 'looc', 'lood', 'looe', 'loof', 'loog', 'looh', 'looi', 'looj', 'look', 'lool', 'loom', 'loon', 'looo', 'loop', 'looq', 'loor', 'loos', 'loou', 'loov', 'loow', 'loox', 'looy', 'looz', 'lopt', 'loqt', 'lort', 'lost', 'lott', 'lout', 'lovt', 'lowt', 'loxt', 'loyt', 'lozt', 'lpot', 'lqot', 'lrot', 'lsot', 'ltot', 'luot', 'lvot', 'lwot', 'lxot', 'lyot', 'lzot', 'moot', 'noot', 'ooot', 'poot', 'qoot', 'root', 'soot', 'toot', 'uoot', 'voot', 'woot', 'xoot', 'yoot', 'zoot']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_manipulation(word):\n",
    "    \"\"\"\n",
    "        Here we use a seperate string for replacing each letter - alphabets\n",
    "        Prepare a list of tuples that are broken at each index - word_tuples\n",
    "        For every tuple (L, R) replace R[0] with 'c' in alphabets\n",
    "    \"\"\"\n",
    "    alphabets = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    word_tuples = [(word[:i],word[i:]) for i in range(len(word))]\n",
    "    return [L + c + R[1:] for L, R in word_tuples for c in alphabets if c != R[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aoot', 'boot', 'coot', 'doot', 'eoot', 'foot', 'goot', 'hoot', 'ioot', 'joot', 'koot', 'moot', 'noot', 'ooot', 'poot', 'qoot', 'root', 'soot', 'toot', 'uoot', 'voot', 'woot', 'xoot', 'yoot', 'zoot', 'laot', 'lbot', 'lcot', 'ldot', 'leot', 'lfot', 'lgot', 'lhot', 'liot', 'ljot', 'lkot', 'llot', 'lmot', 'lnot', 'lpot', 'lqot', 'lrot', 'lsot', 'ltot', 'luot', 'lvot', 'lwot', 'lxot', 'lyot', 'lzot', 'loat', 'lobt', 'loct', 'lodt', 'loet', 'loft', 'logt', 'loht', 'loit', 'lojt', 'lokt', 'lolt', 'lomt', 'lont', 'lopt', 'loqt', 'lort', 'lost', 'lott', 'lout', 'lovt', 'lowt', 'loxt', 'loyt', 'lozt', 'looa', 'loob', 'looc', 'lood', 'looe', 'loof', 'loog', 'looh', 'looi', 'looj', 'look', 'lool', 'loom', 'loon', 'looo', 'loop', 'looq', 'loor', 'loos', 'loou', 'loov', 'loow', 'loox', 'looy', 'looz']\n"
     ]
    }
   ],
   "source": [
    "print(replace_manipulation(\"loot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0.4 Insert_manipulation\n",
    "\n",
    "    1) Repeat the step 01 of replace, except we need the duplicate term (\"word\",\"\"). Hence use range(len(word)+1)\n",
    "    2) For inserting a new alphabet at every other index: L + c + R where (L, R) are tuples and c is alphabet from \"abcd...xyz\"\n",
    "    \n",
    "`['aloot', 'bloot', 'cloot', 'dloot', 'eloot', 'floot', 'gloot', 'hloot', 'iloot', 'jloot', 'kloot', 'lloot', 'mloot', 'nloot', 'oloot', 'ploot', 'qloot', 'rloot', 'sloot', 'tloot', 'uloot', 'vloot', 'wloot', 'xloot', 'yloot', 'zloot', 'laoot', 'lboot', 'lcoot', 'ldoot', 'leoot', 'lfoot', 'lgoot', 'lhoot', 'lioot', 'ljoot', 'lkoot', 'lloot', 'lmoot', 'lnoot', 'looot', 'lpoot', 'lqoot', 'lroot', 'lsoot', 'ltoot', 'luoot', 'lvoot', 'lwoot', 'lxoot', 'lyoot', 'lzoot', 'loaot', 'lobot', 'locot', 'lodot', 'loeot', 'lofot', 'logot', 'lohot', 'loiot', 'lojot', 'lokot', 'lolot', 'lomot', 'lonot', 'looot', 'lopot', 'loqot', 'lorot', 'losot', 'lotot', 'louot', 'lovot', 'lowot', 'loxot', 'loyot', 'lozot', 'looat', 'loobt', 'looct', 'loodt', 'looet', 'looft', 'loogt', 'looht', 'looit', 'loojt', 'lookt', 'loolt', 'loomt', 'loont', 'looot', 'loopt', 'looqt', 'loort', 'loost', 'loott', 'loout', 'loovt', 'loowt', 'looxt', 'looyt', 'loozt', 'loota', 'lootb', 'lootc', 'lootd', 'loote', 'lootf', 'lootg', 'looth', 'looti', 'lootj', 'lootk', 'lootl', 'lootm', 'lootn', 'looto', 'lootp', 'lootq', 'lootr', 'loots', 'loott', 'lootu', 'lootv', 'lootw', 'lootx', 'looty', 'lootz']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_manipulation(word):\n",
    "    alphabets = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    word_tuples = [(word[:i],word[i:]) for i in range(len(word)+1)] #we add the last combination ('word', '')\n",
    "    return [L + c + R for L, R in word_tuples for c in alphabets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aloot', 'bloot', 'cloot', 'dloot', 'eloot', 'floot', 'gloot', 'hloot', 'iloot', 'jloot', 'kloot', 'lloot', 'mloot', 'nloot', 'oloot', 'ploot', 'qloot', 'rloot', 'sloot', 'tloot', 'uloot', 'vloot', 'wloot', 'xloot', 'yloot', 'zloot', 'laoot', 'lboot', 'lcoot', 'ldoot', 'leoot', 'lfoot', 'lgoot', 'lhoot', 'lioot', 'ljoot', 'lkoot', 'lloot', 'lmoot', 'lnoot', 'looot', 'lpoot', 'lqoot', 'lroot', 'lsoot', 'ltoot', 'luoot', 'lvoot', 'lwoot', 'lxoot', 'lyoot', 'lzoot', 'loaot', 'lobot', 'locot', 'lodot', 'loeot', 'lofot', 'logot', 'lohot', 'loiot', 'lojot', 'lokot', 'lolot', 'lomot', 'lonot', 'looot', 'lopot', 'loqot', 'lorot', 'losot', 'lotot', 'louot', 'lovot', 'lowot', 'loxot', 'loyot', 'lozot', 'looat', 'loobt', 'looct', 'loodt', 'looet', 'looft', 'loogt', 'looht', 'looit', 'loojt', 'lookt', 'loolt', 'loomt', 'loont', 'looot', 'loopt', 'looqt', 'loort', 'loost', 'loott', 'loout', 'loovt', 'loowt', 'looxt', 'looyt', 'loozt', 'loota', 'lootb', 'lootc', 'lootd', 'loote', 'lootf', 'lootg', 'looth', 'looti', 'lootj', 'lootk', 'lootl', 'lootm', 'lootn', 'looto', 'lootp', 'lootq', 'lootr', 'loots', 'loott', 'lootu', 'lootv', 'lootw', 'lootx', 'looty', 'lootz']\n"
     ]
    }
   ],
   "source": [
    "print(insert_manipulation(\"loot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 n_edits\n",
    "\n",
    "'n' referes to the number of `edits(insert, replace, delete, switch)` required to retrieve the target word.\n",
    "\n",
    "Mostly the highest edits recommended would be n = 2. Considering this fact we shall implement two methods one that implements one_edit and other n-edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_edit_correction(word, do_swap):\n",
    "    \n",
    "    one_edit_set = set()\n",
    "    one_edit_set = set(insert_manipulation(word) + delete_manipulation(word) + replace_manipulation(word))\n",
    "    \n",
    "    if do_swap:\n",
    "        one_edit_set |= swap_manipulation(word)\n",
    "    \n",
    "    return one_edit_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_edit_correction(word, do_swap, n=2,):\n",
    "    \n",
    "    multi_edit_set = set()\n",
    "    one_edit_set = one_edit_correction(word, do_swap)\n",
    "    for i in range(n-1):\n",
    "        multi_edit_set = set()\n",
    "        for w in one_edit_set:\n",
    "            multi_edit_set |= one_edit_correction(w, do_swap)\n",
    "        one_edit_set = multi_edit_set\n",
    "        \n",
    "    return multi_edit_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Corrections\n",
    "\n",
    "Now that we have implemented the two_edits as per our requirement, we shall implement a method that:\n",
    "\n",
    "    1) Collects both one-edit and two-edit words.\n",
    "    2) Extract the words that are defined in the vocabulary.\n",
    "    3) Map the probabilities of these extracted words.\n",
    "    4) Sort and return the 'n' best possible words for the given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_best_words(word, probs_words, vocabulary, n=2, do_swap=False):\n",
    "    recommendations = {}\n",
    "    n_best = []\n",
    "\n",
    "    if word in vocabulary:\n",
    "        recommendations = {word: probs_words[word]}\n",
    "        \n",
    "    recommendations.update({K: probs_words[K] for K in one_edit_correction(word, do_swap) if K in vocabulary})\n",
    "    recommendations.update({K: probs_words[K] for K in multi_edit_correction(word, do_swap, n) if K in vocabulary})\n",
    "    \n",
    "    recommendations = sorted(recommendations, key=recommendations.get)[:n]\n",
    "    \n",
    "    n_best = set((K, probs_words[K]) for K in recommendations)\n",
    "\n",
    "    return n_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Edit Distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
    "\n",
    "    m = len(source) \n",
    "    n = len(target) \n",
    "\n",
    "    D = np.zeros((m+1, n+1), dtype=int) \n",
    "    \n",
    "    \n",
    "    for row in range(m+1): \n",
    "        D[row,0] = row\n",
    "        \n",
    "    for col in range(n+1): \n",
    "        D[0,col] = col\n",
    "        \n",
    "    for row in range(1,m+1): \n",
    "        \n",
    "        for col in range(1,n+1):\n",
    "            \n",
    "            r_cost = 0\n",
    "             \n",
    "            if source[row-1] == target[col-1]:\n",
    "                r_cost = 0\n",
    "                \n",
    "            D[row,col] = min(D[row-1][col]+del_cost, D[row][col-1]+ins_cost, D[row-1][col-1]+(source[row-1]!=target[col-1])*rep_cost)\n",
    "          \n",
    "    med = D[m][n]\n",
    "    return D, med"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Output\n",
    "\n",
    "Replace the word with manual input and check the corrected words.\n",
    "\n",
    "`Note: Please understand that these suggestions are based on the corpus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('rear', 1.865184466743761e-05), ('nice', 1.865184466743761e-05)}\n",
      "{('chair', 1.865184466743761e-05), ('diff', 1.865184466743761e-05), ('infer', 1.865184466743761e-05)}\n"
     ]
    }
   ],
   "source": [
    "word = \"niar\"\n",
    "print(n_best_words(word,word_probability,vocabulary,2, False))\n",
    "print(n_best_words(word,word_probability,vocabulary,3, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
